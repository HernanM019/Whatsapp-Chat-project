{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import dateparser\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to load our Chat.txt into Python and read it. We will do this using the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Chat.txt', \"r\", encoding='utf-8') as infile:\n",
    "    output_Data = { 'DateTime': [], 'Name': [], 'Content': [] }\n",
    "    for line in infile:\n",
    "        matches = re.match(r'^(\\d{1,2})\\/(\\d{1,2})\\/(\\d\\d), (24:00|2[0-3]:[0-5][0-9]|[0-1][0-9]:[0-5][0-9]) - ((\\S[^:]*?): )?(.*)$', line)\n",
    "        if matches:\n",
    "          output_Data['DateTime'].append(\n",
    "            datetime(\n",
    "              int(matches.group(3))+2000,\n",
    "              int(matches.group(1)),\n",
    "              int(matches.group(2)),\n",
    "              hour=int(matches.group(4)[0:2]),\n",
    "              minute=int(matches.group(4)[3:])\n",
    "            ))\n",
    "          output_Data['Name'].append(matches.group(6) or \"{undefined}\")\n",
    "          output_Data['Content'].append(matches.group(7))\n",
    "\n",
    "        elif len(output_Data['Content']) > 0:\n",
    "          output_Data['Content'][-1] += \"\\n\" + line[0:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Name</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-15 06:31:00</td>\n",
       "      <td>{undefined}</td>\n",
       "      <td>Messages to this group are now secured with en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-11 09:41:00</td>\n",
       "      <td>{undefined}</td>\n",
       "      <td>Analoh RESAGRATIA created group \"RESA\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-15 06:31:00</td>\n",
       "      <td>{undefined}</td>\n",
       "      <td>You joined using this group's invite link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-15 07:06:00</td>\n",
       "      <td>AcidiQ</td>\n",
       "      <td>Good morning Fam.\\nI just went through the Bud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-15 07:29:00</td>\n",
       "      <td>+234 805 230 5080</td>\n",
       "      <td>Sounds great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime               Name  \\\n",
       "0 2019-11-15 06:31:00        {undefined}   \n",
       "1 2019-11-11 09:41:00        {undefined}   \n",
       "2 2019-11-15 06:31:00        {undefined}   \n",
       "3 2019-11-15 07:06:00             AcidiQ   \n",
       "4 2019-11-15 07:29:00  +234 805 230 5080   \n",
       "\n",
       "                                             Content  \n",
       "0  Messages to this group are now secured with en...  \n",
       "1             Analoh RESAGRATIA created group \"RESA\"  \n",
       "2          You joined using this group's invite link  \n",
       "3  Good morning Fam.\\nI just went through the Bud...  \n",
       "4                                       Sounds great  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(output_Data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove messages where Name is 'undefined' as these represent system messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length of df before:{}\".format(len(df)))\n",
    "#Remove messages where Name is 'undefined' as these represent system messages.\n",
    "df = df[~df[\"Name\"].str.contains(\"undefined\")]\n",
    "print(\"length of df after:{}\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Content\"].str.contains('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Content\"] = df[\"Content\"].replace('\\n', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Content\"].str.contains('\\n')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create Columns for Date, Time, Word Count etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = [datetime.date(d) for d in df['DateTime']] \n",
    "df[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time'] = [datetime.time(d) for d in df['DateTime']]\n",
    "df[\"Time\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hour'] = df.DateTime.dt.hour\n",
    "df[\"Hour\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df['DateTime'].apply(lambda x: x.day_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Word_Count'] = df['Content'].str.count(' ') + 1\n",
    "df['Letter_Count'] = df['Content'].apply(lambda s : len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to csv format\n",
    "df.to_csv(\"WhatsappChat1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will clean our chat data by removing all messages in join and also removing all empty lines (lines that contain no message) by running the code below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove new lines\n",
    "chat = [line.strip() for line in chat]\n",
    "chat[:10]\n",
    "print(\"length of chat is:\")\n",
    "print(len(chat))\n",
    "\n",
    "#Clean out the join notification lines\n",
    "clean_chat = [line for line in chat if not \"joined using this\" in line]\n",
    "\n",
    "#Further cleaning\n",
    "#Remove empty lines\n",
    "clean_chat = [line for line in clean_chat if len(line) > 1]\n",
    "print(\"length of clean_chat is:\")\n",
    "print(len(clean_chat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next we do the same for messages that show members who left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop 'left-ers'\n",
    "left = [line for line in clean_chat if line.endswith(\"left\")]\n",
    "left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the RESAGRATIA Whatsapp Chat, no members left in the period covered by this analysis as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all that 'left'\n",
    "#Clean out the left notification lines\n",
    "clean_chat = [line for line in clean_chat if not line.endswith(\"left\")]\n",
    "print(len(clean_chat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will group all the lines in clean_chat into messages and store in a variable named msgs. Every message begins with a date e.g 12/12/19 and we will use this property in grouping. We will make use of the regex package in Python by running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge messages that belong together\n",
    "msgs = [] #message container\n",
    "pos = 0 #counter for position of msgs in the container\n",
    "\"\"\"\n",
    "Flow:\n",
    "For every line, see if it matches the expression which is starting with the format \"number(s)+slash\" eg \"12/\"\n",
    "If it does, it is a new line of conversion as they begin with dates, add it to msgs container\n",
    "Else, it is a continuation of the previous line, add it to the previous line and append to msgs, then pop previous line.\n",
    "\"\"\"\n",
    "for line in clean_chat:\n",
    "    if re.findall(\"\\A\\d+[/]\", line):\n",
    "        msgs.append(line)\n",
    "        pos += 1\n",
    "    else:\n",
    "        take = msgs[pos-1] + \". \" + line\n",
    "        msgs.append(take)\n",
    "        msgs.pop(pos-1)\n",
    "\n",
    "len(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 1472 unique messages (This should be different for your data).\n",
    "Let’s look at the content of our msgs data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will need to extract Date, Time, Name and Message Content from our msgs data using the codes below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = [msgs[i].split(',')[1].split('-')[0] for i in range(len(msgs))]\n",
    "time = [s.strip(' ') for s in time] # Remove spacing\n",
    "print(\"length of time is:\")\n",
    "print(len(time))\n",
    "time[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [msgs[i].split(',')[0] for i in range(len(msgs))]\n",
    "len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get name\n",
    "name = [msgs[i].split('-')[1].split(':')[0] for i in range(len(msgs))]\n",
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "content = []\n",
    "for i in range(len(msgs)):\n",
    "  try:\n",
    "    content.append(msgs[i].split(':')[2])\n",
    "  except IndexError:\n",
    "    content.append('Missing Text')\n",
    "len(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally use the pandas library to merge our date, time, name and content data into a Dataframe named df using the code below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(date, time, name, content)), columns = ['Date', 'Time', 'Name', 'Content'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first two rows of data. The Content column shows “Missing Text.” Those are system messages and we’ll need to drop them. We can do this using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Content\"]!='Missing Text']\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Content\"]!='Missing Text']\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create additional columns by taking advantage of built-in functions in pandas. First let us create a Datetime column by merging Date and Time columns and using the pd.to_datetime function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "df['DateTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our newly created Datetime column we can create a weekday column showing days of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df['DateTime'].apply(lambda x: x.day_name()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split our Content column to create new columns showing the number of letters and words contained in each message. We will call these columns Letter_count and Word_count respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Letter_Count'] = df['Content'].apply(lambda s : len(s))\n",
    "df['Word_Count'] = df['Content'].apply(lambda s : len(s.split(' ')))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will split our Time column to create a new column named Hour showing the hour of the day a message was sent. For example given 12:15, we will split the data before the colon (12) as this indicates hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hour'] = df['Time'].apply(lambda x : x.split(':')[0]) \n",
    "# The first token of a value in the Time Column contains the hour (Eg., \"20\" in \"20:15\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go on and create visuals using matplotlib and pandas but for this tutorial we will be creating only a WordCloud visual showing the most used words in the Group Chat. Word-clouds are used to perform high-level analysis and visualization of text data. The other visuals will be created using Power BI.\n",
    "First we will need to further clean our data. Remember when we exported our data from Whatsapp, we selected the WITHOUT MEDIA option. Python indicates all those instances where the media was removed with a “<Media Omitted>” message. \n",
    "Also all messages that were deleted are indicated by the system message “This message was deleted.” \n",
    "NB: I did not remove deleted messages as I intend to use them in creating visuals.\n",
    "Let’s go ahead and explore our data to confirm these presumptions.\n",
    "We will use pandas built in function to list the count of unique messages in our Content column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"Content\"].value_counts().to_frame().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be slightly different for your data but you should see “<Media omitted>” and “This message was deleted.” “https” shows instances where a web url was shared in the group.\n",
    "To create our WordCloud, we will make use of Vectorized String Operations in Python to remove instances where “<Media omitted>” and “This message was deleted” occur in our data. We will store this in a variable named “wordcloud_df.” We will still retain our original Dataframe df as we will use it to create visuals in Power BI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of df:\")\n",
    "print(df.shape)\n",
    "#remove instances where \"<Media omitted occur\"\n",
    "wordcloud_df = df[~df[\"Content\"].str.contains(\"<Media omitted>\")]\n",
    "#remove instances where \"This message was deleted occur\"\n",
    "wordcloud_df = wordcloud_df[~df[\"Content\"].str.contains(\"This message was deleted\")]\n",
    "print(\"shape of wordcloud_df:\")\n",
    "print(wordcloud_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our WordCloud visual using the wordcloud_df:\n",
    "First we will create a function that generates the frequency of words in our data and returns the top 20 words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_freq(text):\n",
    "    #Will store the list of words\n",
    "    word_list = []\n",
    "\n",
    "    #Loop over all the tweets and extract words into word_list\n",
    "    for tw_words in text.split():\n",
    "        word_list.extend(tw_words)\n",
    "\n",
    "    #Create word frequencies using word_list\n",
    "    word_freq = pd.Series(word_list).value_counts()\n",
    "\n",
    "    #Print top 20 words\n",
    "    word_freq[:20]\n",
    "    \n",
    "    return word_freq\n",
    "\n",
    "gen_freq(wordcloud_df.Content.str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a function that removes punctuations and converts every word to lower-case to ensure uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #Remove RT\n",
    "    text = re.sub(r'RT', '', text)\n",
    "    \n",
    "    #Fix &\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "    \n",
    "    #Remove punctuations\n",
    "    text = re.sub(r'[?!.;:,#@-]', '', text)\n",
    "     \n",
    "    #Convert to lowercase to maintain consistency\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using stopwords we imported from wordcloud\n",
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go ahead and create our WordCloud visual using the functions we created above and the wordcloud package we imported earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "text = wordcloud_df.Content.apply(lambda x: clean_text(x))\n",
    "word_freq = gen_freq(text.str)*100\n",
    "word_freq = word_freq.drop(labels=STOPWORDS, errors='ignore')\n",
    "\n",
    "#Generate word cloud\n",
    "wc = WordCloud(width=450, height=400, max_words=300, background_color='white').generate_from_frequencies(word_freq)\n",
    "\n",
    "plt.figure(figsize=(14, 18))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig('wordcloud.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can superimpose the words onto a mask of any shape. For this tutorial, I will be using a mask of a chat icon. \n",
    "Using numpy we will download and save the mask to a variable named image_mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image_mask = np.array(Image.open('Chaticon.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#visualizing the mask\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(14) # set width\n",
    "fig.set_figheight(18) # set height\n",
    "\n",
    "plt.imshow(image_mask, cmap=plt.cm.gray, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot our WordCloud image superimposed on the image_mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "text = wordcloud_df.Content.apply(lambda x: clean_text(x))\n",
    "word_freq = gen_freq(text.str)*100\n",
    "word_freq = word_freq.drop(labels=STOPWORDS, errors='ignore')\n",
    "\n",
    "#Generate word cloud\n",
    "wc = WordCloud(width=450, height=400, max_words=300, mask=image_mask, background_color='white').generate_from_frequencies(word_freq)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig('wordcloud1.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save our Dataframe df in csv format by using pandas built in function. This csv will be used in creating our visuals in Power BI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to csv format\n",
    "df.to_csv(\"WhatsappChat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "minimal_ds",
   "language": "python",
   "name": "minimal_ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
